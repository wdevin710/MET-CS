list(
x = 0.8,
y = 0.4,
text = "Low",
xref = "paper",
yref = "paper",
xanchor = "center",
yanchor = "bottom",
showarrow = FALSE
))
figdis <- subplot(figdis1, figdis2, figdis3, figdis4, nrows = 2)%>%
layout(title = 'Distribution for all variables', annotations = annotations)
figdis
X <- DF %>%
mutate(Year = year(Date),Month = month(Date),
.after = Date)
X <- X %>%
group_by(Year, Month)%>%
summarise(Open = mean(Open),
Volume = mean(Volume),
High = mean(High),
Low = mean(Low))
X <- X %>%
mutate(date = make_date(Year, Month), .before=Year)%>%
subset( select = c('date','Open','Volume','High','Low'))
fig2 <- plot_ly(X, type = 'scatter', mode = 'lines')%>%
add_trace(x = ~date, y = ~Open, name = 'Open')%>%
add_trace(x = ~date, y = ~Volume, name= 'Volume')%>%
add_trace(x = ~date, y = ~High, name= 'High')%>%
add_trace(x = ~date, y = ~Low, name= 'Low')%>%
layout(title = "Trend of Variables by mean",
xaxis = list(title = "Year"),
yaxis = list (title = "Value"))
fig2
set.seed(100)
samples <- 1000
sample <- numeric(samples)
par(mfrow = c(2,2))
for (size in c(10, 20, 30, 40)) {
for (i in 1:samples) {
sample[i] <- mean(sample(DF$Open, size = size,
replace = FALSE))
}
hist(sample, prob = TRUE,
main = paste("Sample Size =", size))
cat("Sample Size = ", size, " Mean = ", mean(sample),
" SD = ", sd(sample), "\n")
}
par(mfrow = c(1,1))
#data2 <- Twitter %>%
#  subset(Year == 2017)
a <- sample(2, nrow(Twitter), replace = TRUE, prob = c(0.6,0.4))
set.seed(100)
data1 <- Twitter[a == 1,]
data2 <- Twitter[a == 2,]
#data1 <- subset(data1,select = c(2:6))
#data2 <- subset(data2,select = c(2:6))
## We start to label it. 0 mean gain, 1 mean lose. When Open = Close, we gain.
data1$Label <- ifelse(data1$Open > data1$Close, 1,
ifelse(data1$Open < data1$Close , 0, 0))
data1 <- subset(data1, select = c('Open','High','Low','Volume','Label'))
data2$Label <- ifelse(data2$Open > data2$Close, 1,
ifelse(data2$Open < data2$Close , 0, 0))
data2 <- subset(data2, select = c('Open','High','Low','Volume','Label'))
data1$Label <- as.factor(data1$Label)
data2$Label <- as.factor(data2$Label)
library(randomForestSRC)
library(caret)
n <- length(names(data1))
set.seed(100)
## Select mtry number
for(i in 1:6){
mtry <- rfsrc(Label~., data1, mtry=i)
error <- mean(mtry$err.rate, na.rm = TRUE)
print(error)
}
## Select 5 as mtry paramter
set.seed(100)
## Find out best ntree
ntree <-rfsrc(Label~.,data1,mtry=4, ntree=800, importance = TRUE)
plot(ntree)
## Start to modeling, then plot
rf <- rfsrc(Label~., data1, mtry=4, ntree = 400, importance = TRUE)
rf
## Use model to predict gain or lose, then output confusion_matrix
pred1 <-predict.rfsrc(rf,data2)
cf <- table(data2$Label, pred1$class, dnn = c('Actual','Predicted'))
cf
rf
if (!is.element("stringr", installed.packages()[,"Package"]))
install.packages("stringr", repos="http://cran.us.r-project.org",
dependencies = TRUE)
library(stringr)
# Join - str_c
str_c(c(1,2))
str_c(c("a", "b"), c(1,2), c("c", "d"))
str_c(c("a", "b"), c(1,2), c("c", "d"), sep = "-")
str_c("Letter: ", letters)
str_c("Letter", letters, sep = ": ")
str_c(LETTERS, " is for", "...")
str_c(LETTERS, c(" is for", " for"), "...")
str_c(letters[-26], " is before ", letters[-1])
str_c(c(1,2), collapse = "")
str_c(c("a", "b"), c(1,2), c("c", "d"), collapse=":")
str_c(c("a", "b"), c(1,2), c("c", "d"), sep = "-", collapse=":")
str_c(letters, collapse = "")
str_c(letters, collapse = ":")
str_flatten(letters)
str_flatten(letters, collapse = ":")
# Missing inputs give missing outputs
str_c(c("a", NA, "b"), "-d")
str_length(c("a", "b", "c"))
which.max(str_length(c("a", "b", "c")))
s <- "United States"
str_length(s)
str_sub(s, 1, 6)
str_sub(s, end = 6)
str_sub(s, start = 2, end = 5)
str_sub(s, start = 1, end = 2)
s <- c("United States",'HOME')
str_length(s)
str_sub(s, start = 1, end = 2)
str_sub(s, -2)
head(fruit)
tail(fruit)
length(fruit)
fruit[str_detect(fruit, "ap")]
data <- c(
"123 Main St",
"6175551234",
"978-356-1234",
"Work: 617-423-4567; Home: 508.555.3589; Cell: 555 777 3456"
)
phone <- "([2-9][0-9]{2})([- .]?)([0-9]{3})([- .])?([0-9]{4})"
# Which strings contain phone numbers?
str_detect(data, phone)
str_match(data, phone)
str_match_all(data, phone)
str_locate_all("This is cs544", "is")
str_extract_all("This is cs544", "is", simplify = TRUE)
str_locate_all("This is cs544", "\\bis\\b")
str_extract_all("This is cs544", "\\bis\\b", simplify = TRUE)
# Trimming
x <- "    How     are \n you?\t"
x
str_trim(x)
str_trim(x, side="left")
str_trim(x, side="right")
x <- "    How     are \n you?\t"
str_squish(x)
x <- "\t   How\t\t  \t\tare\tyou?"
str_squish(x)
str_trim("  String with trailing and leading white space\t")
str_trim("\n\nString with trailing and leading white space\n\n", side = "right")
str_pad("cs544", 10)
str_pad("cs544", 10, pad = "_")
rbind(
str_pad("cs544", 10, "left"),
str_pad("cs544", 10, "right"),
str_pad("cs544", 10, "both")
)
str_pad(c("a", "abc", "abcdef"), 5)
str_pad("a", c(2, 4, 6))
x <- c("what", "video", "cross", "extra", "deal", "authority")
y <-  c('a','e','i','o','u')
str_detect(x,y)
str_locate(x,y)
x <- "Hello, how are you? I am fine, thank you."
str_length(x)
str_count(x, boundary("sentence"))
rm(list=ls()); cat("\014") ## clear workspace
Twitter <- read.csv(file = 'DATA/TWTR.csv')
head(Twitter)
library(dplyr)
library(ggplot2)
library(plotly)
library(tibbletime)
library(lubridate)
library(reshape2)
##Check Null value
Twitter <- na.omit(Twitter)
which(is.na(Twitter))
Twitter$Date <- as.Date(Twitter$Date)
View(Twitter)
## Drop 2013 stock data, because it is small size and useless
Twitter <- Twitter %>%
mutate(Year = year(Date))
Twitter <- subset(Twitter, Twitter['Year'] > 2013)
## Get the varaible which we need to use
DF <- Twitter %>%
summarise(Date = Date,Open = Open,High = High, Low = Low, Volume = round(Volume/1000000, 2))
View(DF)
## Set Column "Date" as date format
DF$Date <- as.Date(DF$Date)
fig <- plot_ly(DF, x = ~Date, y = ~Open, name = 'Open', type = 'scatter', mode = 'lines')
fig <- fig %>% add_trace(y = ~Volume, name = 'Volume', mode = 'lines')
fig <- fig %>% add_trace(y = ~High, name = 'High', mode = 'lines')
fig <- fig %>% add_trace(y = ~Low,  name = 'Low', mode = 'lines')
fig <- fig %>% layout(title = "Variable Trend",
xaxis = list(title = "Date"),
yaxis = list (title = "Value"))
fig
## Draw Box plot
figbox <- plot_ly(y = ~DF$Open, type = "box",name="Open")
figbox <- figbox %>% add_trace(y = ~DF$Volume, name="Volume")
figbox <- figbox %>% add_trace(y = ~DF$High, name="High")
figbox <- figbox %>% add_trace(y = ~DF$Low, name="Close")
figbox <- figbox %>% layout(title = "Boxplot for Open and Volume",
xaxis = list(title = "Variables"),
yaxis = list (title = "Value"))
figbox
## Draw the distribution of all variable
y1 <- dnorm(DF$Open,mean = mean(DF$Open), sd = sd(DF$Open))
y2 <- dnorm(DF$Volume,mean = mean(DF$Volume), sd = sd(DF$Volume))
y3 <- dnorm(DF$High,mean = mean(DF$High), sd = sd(DF$High))
y4 <- dnorm(DF$Low,mean = mean(DF$Low), sd = sd(DF$Low))## Draw distribution
figdis1 <- plot_ly(DF, x = ~DF$Open, y = y1, type = 'scatter', mode = 'markers')
figdis1 <- figdis1 %>% layout(title = "Distribution of Open",
xaxis = list(title = "Open"),
yaxis = list (title = "Destiny"))
figdis2 <- plot_ly(DF, x = ~DF$Volume, y = y2, type = 'scatter', mode = 'markers')
figdis2 <- figdis2 %>% layout(title = "Distribution of Open",
xaxis = list(title = "Volume"),
yaxis = list (title = "Destiny"))
figdis3 <- plot_ly(DF, x = ~DF$High, y = y3, type = 'scatter', mode = 'markers')
figdis3 <- figdis3 %>% layout(title = "Distribution of Open",
xaxis = list(title = "High"),
yaxis = list (title = "Destiny"))
figdis4 <- plot_ly(DF, x = ~DF$Low, y = y4, type = 'scatter', mode = 'markers')
figdis4 <- figdis4 %>% layout(title = "Distribution of Open",
xaxis = list(title = "Low"),
yaxis = list (title = "Destiny"))
annotations = list(
list(
x = 0.2,
y = 1.0,
text = "Open",
xref = "paper",
yref = "paper",
xanchor = "center",
yanchor = "bottom",
showarrow = FALSE
),
list(
x = 0.8,
y = 1,
text = "Volume",
xref = "paper",
yref = "paper",
xanchor = "center",
yanchor = "bottom",
showarrow = FALSE
),
list(
x = 0.2,
y = 0.4,
text = "High",
xref = "paper",
yref = "paper",
xanchor = "center",
yanchor = "bottom",
showarrow = FALSE
),
list(
x = 0.8,
y = 0.4,
text = "Low",
xref = "paper",
yref = "paper",
xanchor = "center",
yanchor = "bottom",
showarrow = FALSE
))
figdis <- subplot(figdis1, figdis2, figdis3, figdis4, nrows = 2)%>%
layout(title = 'Distribution for all variables', annotations = annotations)
figdis
X <- DF %>%
mutate(Year = year(Date),Month = month(Date),
.after = Date)
X <- X %>%
group_by(Year, Month)%>%
summarise(Open = mean(Open),
Volume = mean(Volume),
High = mean(High),
Low = mean(Low))
X <- X %>%
mutate(date = make_date(Year, Month), .before=Year)%>%
subset( select = c('date','Open','Volume','High','Low'))
fig2 <- plot_ly(X, type = 'scatter', mode = 'lines')%>%
add_trace(x = ~date, y = ~Open, name = 'Open')%>%
add_trace(x = ~date, y = ~Volume, name= 'Volume')%>%
add_trace(x = ~date, y = ~High, name= 'High')%>%
add_trace(x = ~date, y = ~Low, name= 'Low')%>%
layout(title = "Trend of Variables by mean",
xaxis = list(title = "Year"),
yaxis = list (title = "Value"))
fig2
str_count(x, boundary("word"))
x <- "Hello, how are you? I am fine, thank you."
str_length(x)
str_count(x, boundary("sentence"))
str_count(x, boundary("word"))
str_count(x, boundary("character"))
y <-  c('a','e','i','o','u')
str_count(x, boundary(y))
str_count(x, boundary("vowel"))
x <- c("Hello, how are you? I am fine, thank you.", "Good bye!")
str_split(x, boundary("sentence"))
str_split(x, boundary("sentence"), simplify = TRUE)
str_split(x, boundary("word"))
str_split(x, boundary("word"), n = 4)
str_split(x, boundary("character"))
skills <- c("Java", "Python", "R", "Scala", "Spark")
str_detect(skills, "r")
str_detect(skills, y)
str_extract(skills, ".a.")
str_extract(skills, ".a.")
# Basic matches
x <- c("what", "video", "cross", "extra", "deal", "authority")
y <-  c('a','e','i','o','u')
str_extract(x,y)
str_detect(x, y)
str_match(x, y)
y <-  c('a')
y <-  c('a')
str_match(x, y)
sum(str_match(x, y))
str_detect(x, y)
str_count(x, y)
sum(str_count(x, y))
y <-  c('a','e','i','o','u')
sum(str_count(x, y))
sum(str_count(x, 'a'))
sum(str_count(x, 'a'),str_count(x, 'e'),str_count(x, 'i'),str_count(x, 'o'),str_count(x, 'u'))
str_which(x, y)
str_which(x, 'a')
str_detect(x, y)
str_detect(x, 'a')
str_count(x, boundary(y))
str_locate(x,'a')
str_locate(x,y)
str_locate_all(x,y)
str_locate(x,'a')
# Where in the string is the phone number located?
str_locate(data, phone)
data <- c(
"123 Main St",
"6175551234",
"978-356-1234",
"Work: 617-423-4567; Home: 508.555.3589; Cell: 555 777 3456"
)
phone <- "([2-9][0-9]{2})([- .]?)([0-9]{3})([- .])?([0-9]{4})"
# Where in the string is the phone number located?
str_locate(data, phone)
# What are the phone numbers?
str_extract(data, phone)
y <-  c('a,e,i,o,u')
sum(str_count(x, 'a'),str_count(x, 'e'),str_count(x, 'i'),str_count(x, 'o'),str_count(x, 'u'))
str_extract(x, 'a')
y <-  c(a,e,i,o,u)
y <-  c('a','e','i','o','u')
str_extract(x, 'a')
str_extract(x, y)
str_locate(x,y)
str_view(x, y)
str_view(x, "aeiou")
str_view(x, "eiou")
str_view(x, "ou")
str_view(x, "u")
str_view(x, "aeiou", match = TRUE)
str_view(x, "aeiou", match = FALSE)
str_view(x, "[aeiou]", match = FALSE)
str_view(x, "[aeiou]")
count(str_view(x, "[aeiou]"))
str_count((str_view(x, "[aeiou]")))
str_view(x, "[aeiou]", match = TRUE)
str_view(x, "[aeiou]")
str_extract(x, '[aeiou]')
# Basic matches
x <- c("what", "video", "cross", "extra", "deal", "authority")
str_sub(x,'[aeiou]')
str_sub(x,'[aeiou]', match = TRUE)
str_sub(x,'[aeiou]', match = FALSE)
str_sub(stringr::words x,'[aeiou]', match = FALSE)
str_subset( x,'[aeiou]')
str_subset( x,'[aeiou]', match = TRUE)
str_subset( x,'[aeiou]', negate = FALSE)
str_view( x ,'[aeiou]', negate = FALSE)
str_count(x, '[aeiou]')
str_view(x,'[aeiou]')
str_view(x,'[aeiou]{2,}')
str_view(x,'[aeiou]{2,}', match = TRUE)
str_view(x,'[aeiou]{3,}', match = TRUE)
str_view(x,'[aeiou]{2,}', match = TRUE)
str_subset(x,'[aeiou]{2,}')
str_subset(x,'[aeiou]{,2}')
str_subset(x,'[aeiou]{2,}')
head(fruit)
fruit[str_detect(fruit, "it$")]
str_view(x, "^[aeiou]|[aeiou]$", match = TRUE)
str_locate(x,'[aeiou]')
## Data Wrangling
x
str_locate_all(x,'[aeiou]')
## Data Wrangling
x
str_detect(x,'[aeiou]')
str_locate(x,'[aeiou]')
## Data Wrangling
x
skills <- c("Java", "Python", "R", "Scala", "Spark")
str_detect(skills, "r")
str_detect(skills, regex("r"))
str_detect(skills, regex("r", ignore_case = TRUE))
str_extract(skills, ".a.")
str_extract(x, ".[aeiou].")
str_replace(x, '[aeiou]', "?")
str_replace(x, '[aeiou]', "?")
library(stringr)
house <- read.csv("https://kalathur.com/house.csv", stringsAsFactors = FALSE)
View(house)
str_split(house$Name, boundary("word"))
str_split(house$Name, boundary("word"),n =1)
str_extract(house$Name)
str_split(house$Name, boundary("word"))[1,]
str_split(house$Name, boundary("word"))[[1],]
str_split(house$Name, boundary("word"))[[1,],]
a <- str_split(house$Name, boundary("word"))
View(a)
str_split(house$Name, boundary("word"))
str_split(house$Name, boundary("word"))[[1,]]
str_split(house$Name, boundary("word"))[,[1,]]
str_split(house$Name, boundary("word"))[[1]]
str_split(house$Name, boundary("word"))[[,1]]
str_split(house$Name, boundary("word"))[[1]]
str_split(house$Name, boundary("word"))[1]
str_split(house$Name, boundary("word"))[1[]]
str_split(house$Name, boundary("word"))[1[1]]
a <- house$Name
str_split(a, boundary("word"))
str_split(a, boundary("word"))[1]
str_split(a, boundary("word"))[[1]]
str_split(a, boundary("word"))[[1,]]
which(a, i = 'Adam Kinzinger')
which(a,'Adam Kinzinger')
which(a)
a <- house$Name
str_split(a, boundary("word"))
length(a)
b <- str_split(a, boundary("word"))
length(b)
head(b)
b(1)
str_sub(b, 1)
str_sub(house$Name, 1)
a <- str_sub(house$Name, 1)
a <- house$Name
skills <- c("Java", "Python", "R", "Scala", "Spark")
str_extract(skills, "(.)+a(.)+")
str_extract(skills, "^S")
str_extract(skills, "^S(.)+")
str_extract(skills, "a$")
y <- c("Hello, how are you? I am fine, thank you.", "Good bye!")
str_length(y)
str_count(y, boundary("sentence"))
str_count(y, boundary("word"))
str_count(y, boundary("character"))
x <- c("Hello, how are you? I am fine, thank you.", "Good bye!")
str_split(x, boundary("sentence"))
str_split(x, boundary("sentence"), simplify = TRUE)
str_split(x, boundary("word"))
str_split(x, boundary("word"), n = 4)
str_split(x, boundary("word"))
str_split(x, boundary("word"), n = 4)
str_split(x, boundary("character"))
str_split(x, boundary("sentence"))
str_split(x, boundary("sentence"), simplify = TRUE)
b <- str_split(a, boundary("word"), simplify = TRUE)
b
b[,1]
b <- str_split(a, boundary("word"), simplify = TRUE)[,1]
table(b)[1:5]
table(b)
sort(table(b))[1:5]
sort(table(b),decreasing = TRUE)[1:5]
b <- sort(str_split(a, boundary("word"), simplify = TRUE)[,1]),decreasing = TRUE)[1:5]
b <- sort(table(str_split(a, boundary("word"), simplify = TRUE)[,1]),decreasing = TRUE)[1:5]
b
b <- colnames(sort(table(str_split(a, boundary("word"), simplify = TRUE)[,1]),decreasing = TRUE)[1:5])
b
names(b)
b <- names(sort(table(str_split(a, boundary("word"), simplify = TRUE)[,1]),decreasing = TRUE)[1:5])
b
c <- sort(table(str_split(a, boundary("word"), simplify = TRUE)[,1]),decreasing = TRUE)[1:5
str_split(a, boundary("word"), simplify = TRUE)[,1]
a <- str_split(house$Name, boundary("word"))
str_split(a, boundary("word"), simplify = TRUE)[,1]
a <- house$Name
str_split(a, boundary("word"), simplify = TRUE)[,1]
a <- str_split(house$name, boundary("word"), simplify = TRUE)[,1]
a <- house$Name
b <- names(sort(table(str_split(a, boundary("word"), simplify = TRUE)[,1]),decreasing = TRUE)[1:5])
a <- str_split(house$Name, boundary("word"), simplify = TRUE)[,1]
a <- str_split(house$Name, boundary("word"), simplify = TRUE)[,1]
library(stringr)
house <- read.csv("https://kalathur.com/house.csv", stringsAsFactors = FALSE)
a <- str_split(house$Name, boundary("word"), simplify = TRUE)[,1]
b <- names(sort(table(a),decreasing = TRUE)[1:5])
str_locate(a, b)
str_sub(a,b)
str_locate(a,b)
str_locate_all(a,b)
