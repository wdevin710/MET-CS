files.txt <- list.files(dir, pattern ="txt"，full.names=FALSE)
files.txt <- list.files(dir, pattern ="txt",full.names=FALSE)
files.txt <- list.files(dir, pattern ="txt",full.names=FALSE)
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
dir <- file.path('Data')
files.txt <- list.files(dir, pattern ="txt",full.names=FALSE)
files.txt
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
files.txt <- list.files('Data', pattern ="txt",full.names=FALSE)
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
dir <- file.path('Data')
files.txt <- list.files('Data', pattern ="txt",full.names=FALSE)
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data', pattern ="txt",full.names=FALSE)
files.txt
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data', pattern ="txt")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files(path = '.', pattern ="txt")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
setwd("~/Desktop/Boston University Graduate Study/2022 SPRING/MET CS 688/Language Detection/Data")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
files.txt
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('.', pattern ="txt")
files.txt
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data', pattern ="txt")
setwd("~/Desktop/Boston University Graduate Study/2022 SPRING/MET CS 688/Language Detection")
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv('Data',fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(Data,fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
txt.data <- read_tsv(Data\fn)
setwd("~/Desktop/Boston University Graduate Study/2022 SPRING/MET CS 688/Language Detection/Data")
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('.', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = -6, stop = -5)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
setwd("~/Desktop/Boston University Graduate Study/2022 SPRING/MET CS 688/Language Detection")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data/sentence data', pattern ="txt")
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data/sentence data', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data/sentence data', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data/sentence data', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld3::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld3::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
library(countrycode)
install.packages("countrycode")
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld3::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- countrycode::countrycode(Lg.Data.Code) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data/sentence data', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
library(countrycode)
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld3::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- countrycode::countrycode(Lg.Data.Code) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
install.packages("Unicode")
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld3::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)];   # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data/sentence data', pattern ="txt")
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld3::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)];   # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld3::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)];   # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF)
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data/sentence data', pattern ="txt")
Result.cld2.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.cld2.DF, temp1)
}
knitr::kable(Result.cld2.DF) # Display result of Language Detection
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Consolelibrary("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
files.txt <- list.files('Data/sentence data', pattern ="txt")
Result.cld2.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.cld2.DF <- rbind(Result.cld2.DF, temp1)
}
knitr::kable(Result.cld2.DF) # Display result of Language Detection
Result.cld3.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(paste0('Data/sentence data/', fn))
Lg.Data.Code <- cld3::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)];   # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <-  substr(fn,start = 10, stop = 11)# Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, stringsAsFactors = FALSE)
Result.cld3.DF <- rbind(Result.cld3.DF, temp1)
}
knitr::kable(Result.cld3.DF)
x <- seq(212,320)
dnorm(x, mean = 55, sd = 6)
x <- seq(43，62)
dnorm(x, mean = 55, sd = 6)
x <- seq(43,62)
dnorm(x, mean = 55, sd = 6)
dnorm(43, mean = 55, sd = 6)
pnorm(43, mean = 55, sd = 6)
b <- pnorm(62, mean = 55, sd = 6)
a+b
pnorm
a <- 1- pnorm(43, mean = 55, sd = 6)
a+b
runif(20, max = m)
dunif(61, min=40, max=70, lower.tail=FALSE)
dunif(61, min=40, max=70)
1-pnorm(73,mean = 75, sd = 7)
1-pnorm(74,mean = 75, sd = 7)
pnorm(62,mean = 55, sd = 6) - pnorm(43,mean = 55, sd = 6)
pnorm(62,mean = 55, sd = 6) - pnorm(42,mean = 55, sd = 6)
pnorm(62,mean = 55, sd = 6) - pnorm(43,mean = 55, sd = 6)
1- punif(99, min = 1, max = 150)
100/150
1/150
99/150
52/150
1- punif(98, min = 1, max = 150)
1- punif(99, min = 1, max = 150)
qnorm(0.01, mean = 70 , sd = 9)
qnorm(0.01, mean = 70 , sd = 9, lower.tail = FALSE)
1- pnorm(74, mean = 75, sd = 7)
pnorm(62, mean = 55, sd = 6) - pnorm(43, mean = 55, sd = 6)
1- punif(99, min = 1, max = 150)
52/150
dunif(61, min = 40, max = 70)
1/30
dunif(61, min = 40, max = 70)
